{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First let's create a test script for proof of concept. \n",
    "#This is a simple data structure transformation script taken from\n",
    "#Youtuber 'Real Python' at https://www.youtube.com/watch?v=aysceqdGFw8\n",
    "\n",
    "#Let's make the proper imports.\n",
    "import collections\n",
    "import os\n",
    "import time\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serial Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will generate a tuple consisting of scientist names and data about them. Then, the tuple is passed through the 'map' process which performs a simple act on each element of the input tuple. The resulting act is saved in a second tuple and then the next entry is processed.\n",
    "\n",
    "This is performed on one processor on one thread, so the computer must wait for the first entry to finish processing until the second one can begin. \n",
    "\n",
    "With the addition of a time.sleep() requirement, this can take quite some time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Scientist(name='Sean Lewis', field='Astrophysics', born=1994, PhD=False),\n",
      " Scientist(name='Weixiang Yu', field='Astronomy', born=1992, PhD=False),\n",
      " Scientist(name='Jaqueline Moreno', field='Astronomy', born=1991, PhD=True),\n",
      " Scientist(name='Stephen Sclafani', field='Particle', born=1986, PhD=False),\n",
      " Scientist(name='Eli Worth', field='Condensed Matter', born=1993, PhD=False),\n",
      " Scientist(name='David Lioi', field='Biophysics', born=1990, PhD=True))\n",
      "\n",
      "Process 54720 working record Sean Lewis\n",
      "\n",
      "Process 54720 done processing record Sean Lewis\n",
      "\n",
      "Process 54720 working record Weixiang Yu\n",
      "\n",
      "Process 54720 done processing record Weixiang Yu\n",
      "\n",
      "Process 54720 working record Jaqueline Moreno\n",
      "\n",
      "Process 54720 done processing record Jaqueline Moreno\n",
      "\n",
      "Process 54720 working record Stephen Sclafani\n",
      "\n",
      "Process 54720 done processing record Stephen Sclafani\n",
      "\n",
      "Process 54720 working record Eli Worth\n",
      "\n",
      "Process 54720 done processing record Eli Worth\n",
      "\n",
      "Process 54720 working record David Lioi\n",
      "\n",
      "Process 54720 done processing record David Lioi\n",
      "\n",
      "\n",
      "({'age': 26, 'name': 'Sean Lewis'},\n",
      " {'age': 28, 'name': 'Weixiang Yu'},\n",
      " {'age': 29, 'name': 'Jaqueline Moreno'},\n",
      " {'age': 34, 'name': 'Stephen Sclafani'},\n",
      " {'age': 27, 'name': 'Eli Worth'},\n",
      " {'age': 30, 'name': 'David Lioi'})\n",
      "\n",
      " Time to complete:  6.021\n"
     ]
    }
   ],
   "source": [
    "Scientist = collections.namedtuple('Scientist', [\n",
    "    'name',\n",
    "    'field',\n",
    "    'born',\n",
    "    'PhD',\n",
    "])\n",
    "\n",
    "scientists = (\n",
    "    Scientist(name='Sean Lewis', field='Astrophysics', born=1994, PhD=False),\n",
    "    Scientist(name='Weixiang Yu', field='Astronomy', born=1992, PhD=False),\n",
    "    Scientist(name='Jaqueline Moreno', field='Astronomy', born=1991, PhD=True),\n",
    "    Scientist(name='Stephen Sclafani', field='Particle', born=1986, PhD=False),\n",
    "    Scientist(name='Eli Worth', field='Condensed Matter', born=1993, PhD=False),\n",
    "    Scientist(name='David Lioi', field='Biophysics', born=1990, PhD=True)\n",
    ")\n",
    "\n",
    "pprint(scientists)\n",
    "\n",
    "def transform(x):\n",
    "    print('\\nProcess ' + str(os.getpid()) + ' working record ' + str(x.name))\n",
    "    time.sleep(1)\n",
    "    result = {'name': x.name, 'age': 2020 - x.born}\n",
    "    print('\\nProcess ' + str(os.getpid()) + ' done processing record ' + str(x.name))\n",
    "    \n",
    "    return result\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "result = tuple(map(\n",
    "    transform,\n",
    "    scientists\n",
    "))\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "\n",
    "print('\\n')\n",
    "pprint(result)\n",
    "print('\\n Time to complete:  {0:.3f}'.format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can see the input, which computer core is doing the processing for each task, the output, and the total time to complete the cell. Obviously from the output, the same core is processing each task, and we can watch each task crawl its way through. How can we utilize the full capacity of the quad-core processor in the MacBook Pro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Processing\n",
    "### Data-based parallel processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Scientist(name='Sean Lewis', field='Astrophysics', born=1994, PhD=False),\n",
      " Scientist(name='Weixiang Yu', field='Astronomy', born=1992, PhD=False),\n",
      " Scientist(name='Jaqueline Moreno', field='Astronomy', born=1991, PhD=True),\n",
      " Scientist(name='Stephen Sclafani', field='Particle', born=1986, PhD=False),\n",
      " Scientist(name='Eli Worth', field='Condensed Matter', born=1993, PhD=False),\n",
      " Scientist(name='David Lioi', field='Biophysics', born=1990, PhD=True))\n",
      "\n",
      "\n",
      "\n",
      "Process 54738 working record Sean Lewis\n",
      "Process 54741 working record Stephen Sclafani\n",
      "Process 54739 working record Weixiang Yu\n",
      "Process 54742 working record Eli Worth\n",
      "Process 54743 working record David Lioi\n",
      "Process 54740 working record Jaqueline Moreno\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process 54738 done processing record Sean Lewis\n",
      "Process 54741 done processing record Stephen Sclafani\n",
      "Process 54742 done processing record Eli Worth\n",
      "Process 54743 done processing record David Lioi\n",
      "Process 54739 done processing record Weixiang Yu\n",
      "Process 54740 done processing record Jaqueline Moreno\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[{'age': 26, 'name': 'Sean Lewis'},\n",
      " {'age': 28, 'name': 'Weixiang Yu'},\n",
      " {'age': 29, 'name': 'Jaqueline Moreno'},\n",
      " {'age': 34, 'name': 'Stephen Sclafani'},\n",
      " {'age': 27, 'name': 'Eli Worth'},\n",
      " {'age': 30, 'name': 'David Lioi'}]\n",
      "\n",
      " Time to complete:  1.084\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "pprint(scientists)\n",
    "\n",
    "start = time.time()\n",
    "print('\\n')\n",
    "\n",
    "pool = multiprocessing.Pool()\n",
    "result = pool.map(transform, scientists)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print('\\n')\n",
    "pprint(result)\n",
    "print('\\n Time to complete:  {0:.3f}'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are 6 different processors that are active in this execution. They each take on one task, this being the transform function on one data table entry and all execute simultaneously. The result is a process that completes ~6x faster than before! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And Now I'll Go Even Further Beyond! (Task-Based Parallel Processing)\n",
    "\n",
    "# www.github.com/seanlabean/PythonOpenMPI.git\n",
    "\n",
    "## PythonOpenMPI\n",
    "\n",
    "A generalizable python-mpi utility for task-based parallel programming.\n",
    "\n",
    "This implementation of task-based parallel programming consists of one root processor, and any number of worker processors. The root breaks a portion of a job into bite sized chunks (like a single file) which are then sent to the workers. While the workers... well... work, the root sits and waits. When a working finishes with its allotted chunk, it pings the root node and asks for another chunk, which the root node then provides. Therefore no worker is ever left without something to do.\n",
    "\n",
    "This is fundamentally different and more efficient than data-based paralllel processing in which an **entire** job is split into n equally sized chunks (where n is the number of processors) and sent to the worker processors. In this method, when a worker is done processing, it does not need to ask the root node for any more work (since everything has already been distributed to the workers). Therefore, although the task is being completed in parallel, there is a chance that workers will be left idle while they wait for other workers to finish.\n",
    "\n",
    "## Necessary packages\n",
    "In addition to whichever packages you use for your process you wish to parallelize, you will need to ensure you have working installs of the following:\n",
    "\n",
    "* python v3.X\n",
    "* [OpenMPI v4.X.X](https://www.open-mpi.org/software/ompi/v4.0/)\n",
    "* mpi4py python library\n",
    "\n",
    "Ensure you have a properly configured and installed version of OpenMPI with your PATH and PYTHONPATH correctly pointed to the install directory before attempting to `pip install mpi4py`.\n",
    "\n",
    "## Running the test problem\n",
    "To run the test problem:\n",
    "1. `cd` into the `/examples/read_write_parallel` directory.\n",
    "2. do `python gen_empty_files.py` this will create a sub-directory /files within /read_write_parallel and will populate the directory with 10 blank text files of the form file_X.txt where X runs from 0 to 9. The number of test files created can be changed by editing gen_empty_files.py\n",
    "3. do `mpiexec -n {num_procs} python test_script.py` while replacing num_procs with the number of processors you wish to parallelize the task across.\n",
    "\n",
    "The output will reveal the communication between the supervisor processor and the worker processors: transerfing \"to-do\" data around, sending completed messages back, etc. If you wish, you can edit the chunk size within `test_script.py` to see how the total work is broken up and how the individual processers handle differt sizes of data.\n",
    "\n",
    "This particular command line call will only parallelize across a single node of any number of processors. If multiple nodes are needed, you will need to provide mpiexec with a hostfile.\n",
    "\n",
    "## How to parallelize your specific task\n",
    "Upon investigating the perform_task_in_parallel() funciton within `mpi_utilities.py` you will notice that the \"task\" can be any function, with any number of input args and kwargs. If your task can be condensed into a single function with a discrete amount of input work, it can be parallelized with this routine. To utilize, call ```perform_task_in_parallel(your_func, [args], {kwargs}, input_data, chunk_size, rank, size, comm, root, debug=False)```\n",
    "where rank, size, and comm are generated by the initialize_mpi() call. chunk_size is the amount of input work to be sent to each processor when it asks for something to do. [args] and {kwargs} are the arugments and keyword arguments for your_func.\n",
    "\n",
    "This repository is meant to aid other graduate students in the Drexel University Physics Department, the University at large, and beyond.\n",
    "\n",
    "Contributors:\n",
    "\n",
    "- Sean C. Lewis (owner, scl63@drexel.edu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
